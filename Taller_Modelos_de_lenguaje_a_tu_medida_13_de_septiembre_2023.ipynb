{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nanom/llm_adaptation_workshop/blob/main/Taller_Modelos_de_lenguaje_a_tu_medida_13_de_septiembre_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65c9fdf3"
      },
      "source": [
        "# Taller: Modelos de lenguaje a tu medida ü§ñüí¨"
      ],
      "id": "65c9fdf3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32a802c2"
      },
      "source": [
        "¬øQui√©nes somos?\n",
        "------------------\n",
        "\n",
        "* **Hern√°n Maina** - Becario doctoral de CONICET ( [ü§ó](https://huggingface.co/nanom) | [üåê](https://nanom.github.io/) [üì´](mailto:hernan.maina@mi.unc.edu.ar))\n",
        "* **Guido Ivetta** - Becario doctoral de V√≠a Libre y Profesor Ayudante de FAMAF ([ü§ó](https://huggingface.co/guidoivetta) | [üì´](mailto:guidoivetta@mi.unc.edu.ar ))\n",
        "* **Laura Alonso Alemany** - Profesora Asociada de FAMAF ([üê¶](@morlaicassiopea) | [üåê](https://www.cs.famaf.unc.edu.ar/~laura/) | [üì´](mailto:lauraalonsoalemany@unc.edu.ar))\n",
        "* **Luciana Benotti** - Profesora Asociada de FAMAF ([üê¶](@LucianaBenotti) | [üåê](https://benotti.github.io/) | [üì´](mailto:luciana.benotti@unc.edu.ar))\n",
        "\n",
        "<div style=\"text-align:center\">\n",
        " <h4 style=\"font-size:1.5em;margin:5px\"></h4>\n",
        "    <h5 style=\"font-style:normal;font-size:1em;margin:5px\"></h5>\n",
        "    <div style=\"display:inline-block;margin-right:0px;\">\n",
        "        <img src=\"https://vialibre.org.ar/wp-content/uploads/2020/10/banner-2.jpg\" style=\"height:10em;width:auto;\"/>\n",
        "    </div>\n",
        "    <h6 style=\"font-style:normal;font-size:0.9em;margin:5px;\">\n",
        "        <a href=\"https://twitter.com/\" style=\"color:royalblue;\" target=\"_blank\"> @fvialibre</a> -\n",
        "        <a href=\"https://www.vialibre.org.ar/\" style=\"color:royalblue;\" target=\"_blank\">https://www.vialibre.org.ar/</a>\n",
        "    </h6>\n",
        "</div>"
      ],
      "id": "32a802c2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb685a55"
      },
      "source": [
        "## Esquema del taller\n",
        "\n",
        "1. [Modelos de lenguaje](#Modelos-de-lenguaje)\n",
        "2. [Librerias](#Librerias)\n",
        "3. [Probemos modelos](#Probemos-modelos)\n",
        "4. [Personalicemos un modelo](#Personalicemos-un-modelo)\n",
        "\n",
        "*Requerimientos deseables para entender este taller:*\n",
        "* Conocimiento b√°sico de Python\n",
        "* Conocimiento b√°sico en entrenamiento de modelos\n",
        "\n",
        "*Librer√≠as principales utilizadas*:\n",
        "* [ü§ó HuggingFace](https://huggingface.co/)\n",
        "\n",
        "*Agradecimientos*:\n",
        "* **Cristian Cardellino**, por la inspiraci√≥n en la estructura de partes del notebook. Ver [ac√°](https://colab.research.google.com/#fileId=https%3A//huggingface.co/crscardellino/xi-ciai-cba-martin-fierro/blob/main/xi-ciai-cba.ipynb) para m√°s detalles.\n",
        "* **Beatriz Busaniche**, **Nair Carolina** y **Alexia Halvorsen** de la Fundaci√≥n V√≠a Libre por su continuo apoyo.\n",
        "* **Mat√≠as Bordone** y **Librebase C√≥rdoba**, por la organizaci√≥n de la jornada.\n",
        "* **Nicol√°s Wolovick** y a todo el equipo de **CCAD-UNC** por disponibilizar recursos para la creaci√≥n y desarrollo de este taller.\n",
        "* **FAMAF**, por la apertura y predisposici√≥n."
      ],
      "id": "bb685a55"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **IMPORTANTE**\n",
        "\n",
        "* Todas las celdas indicadas con el s√≠mbolo ( ‚ùó ) son obligatorias y necesarias para el correcto funcionamiento de este taller.\n",
        "\n",
        "* Aquellas se√±aladas con ( üîé ) son de profundizaci√≥n de contenido, optativas de leer y computar.\n",
        "\n",
        "* Si una celda contiene el s√≠mbolo ( ‚è≥ ), significa que tomar√° m√°s tiempo en computarse que el promedio. Tener en cuenta para aprovechar al m√°ximo el tiempo disponible del taller."
      ],
      "metadata": {
        "id": "VnE4JoEZ1z7t"
      },
      "id": "VnE4JoEZ1z7t"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEo2e_80I-42"
      },
      "source": [
        "# 0 - Inicializaci√≥n de la notebook"
      ],
      "id": "YEo2e_80I-42"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGOTohldJe8O"
      },
      "outputs": [],
      "source": [
        "# @markdown ‚ùó\n",
        "# Instalaci√≥n de librer√≠as\n",
        "!pip install -U transformers[torch] --quiet\n",
        "!pip install -U tabulate --quiet\n",
        "!pip install -U datasets --quiet"
      ],
      "id": "eGOTohldJe8O"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjgyHGLMJ-TT"
      },
      "outputs": [],
      "source": [
        "# @markdown ‚ùó\n",
        "# Descarga de datasets\n",
        "import os\n",
        "\n",
        "ROOT_PATH = \"llm_adaptation_workshop\"\n",
        "DATASETS_PATH = os.path.join(ROOT_PATH, \"datasets\")\n",
        "\n",
        "%rm -r \"$ROOT_PATH\"\n",
        "!git clone https://github.com/nanom/llm_adaptation_workshop.git \"$ROOT_PATH\""
      ],
      "id": "LjgyHGLMJ-TT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chzUFmPgLcod"
      },
      "outputs": [],
      "source": [
        "# @markdown ‚ùó\n",
        "# Comprobaci√≥n de recursos (GPUs)\n",
        "!nvidia-smi"
      ],
      "id": "chzUFmPgLcod"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb7f3997"
      },
      "source": [
        "# 1 - Modelos de lenguaje"
      ],
      "id": "eb7f3997"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "283ca08c"
      },
      "source": [
        "## ¬øQu√© son los \"modelos de lenguaje\"?\n",
        "\n",
        "- Son modelos estad√≠sticos predictivos, basados en aprendizaje autom√°tico sobre textos.\n",
        "- Su funci√≥n principal es **analizar** y/o **generar** texto de manera autom√°tica.\n",
        "- Se entrenan encontrando patrones en grandes cantidades de texto libre.\n",
        "- Dado un contexto (e.g. una secuencia de palabras), aplican los patrones inferidos para predecir la palabra siguiente, generando texto plausible y coherente.\n",
        "- Si bien los modelos de lenguaje existen desde hace varias d√©cadas en diferentes formas (modelos markovianos, conditional random fields, redes neuronales recurrentes), actualmente cuando alguien habla de un \"Modelo de Lenguaje\", usualmente se refiere a un modelo neuronal de tipo **Transformer**.\n",
        "\n",
        "### ¬øQu√© es un **Transformer**?\n",
        "\n",
        "- Es un tipo de arquitectura de redes neuronales que se introdujo en el paper [\"Attention is All You Need\"](https://arxiv.org/abs/1706.03762).\n",
        "\n",
        "- El tipo de aprendizaje que hacen estas redes est√° basado en **mecanismos de atenci√≥n**, que ayudan al modelo a enfocarse en las partes m√°s determinantes de la informaci√≥n, de forma que el entrenamiento sea m√°s r√°pido y menos costoso que para otras arquitecturas, como las redes neuronales recurrentes.\n",
        "\n",
        "<!-- La idea fundamental detras de un modelo Transformer, es procesar el lenguaje natural de una manera muy eficiente y efectiva, haciendolo ideal para ser aplicado a una gran cantidad de tareas de PLN.-->\n",
        "\n",
        "- Existen diferentes variantes de transformer, de acuerdo a c√≥mo y qu√© parte de sus componentes utilizan:\n",
        "    - Los modelos de traducci√≥n secuencia a secuencia o `Seq2Seq` (e.g. [T5](https://arxiv.org/abs/1910.10683)), tienen un **codificador y decodificador** y son empleados para tareas de transformaci√≥n como traducci√≥n, simplificaci√≥n, cambio de estilo o resumen.\n",
        "    - Los modelos que s√≥lo usan el **codificador** (e.g. [BERT](https://arxiv.org/abs/1810.04805)) se usan para obtener representaciones vectoriales del texto (*embeddings*) que resultan muy √∫tiles para  determinar relaciones de semejanza entre diferentes textos.\n",
        "    - Los modelos basados en el **decodificador** (e.g. [GPT](https://arxiv.org/abs/2005.14165)) se usan para generar texto autom√°ticamente, como respuestas a preguntas, ensayos o cuentos, entre otros.\n",
        "\n",
        "<center><img src='https://heidloff.net/assets/img/2023/02/transformers.png' width=60%></center>\n",
        "\n",
        "**Nota:** *Para una explicaci√≥n m√°s sencilla, pero m√°s detallada, sugiero los posts de la serie \"The Illustrated...\" de [Jay Alammar](http://jalammar.github.io/):*\n",
        "- [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)\n",
        "- [The Illustrated BERT](http://jalammar.github.io/illustrated-bert/)\n",
        "- [The Illustrated GPT-2](http://jalammar.github.io/illustrated-gpt2/) / [How GPT-3 Works](http://jalammar.github.io/how-gpt3-works-visualizations-animations/)"
      ],
      "id": "283ca08c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87d1ca59"
      },
      "source": [
        "## Probamos un BERT mediante la tarea *fill-mask*\n",
        "\n",
        "En esta secci√≥n vamos a practicar con [BERT](https://en.wikipedia.org/wiki/BERT_(language_model)), un modelo de lenguaje con una arquitectura compuesta de **codificadores** (encoders).\n"
      ],
      "id": "87d1ca59"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IFLq1qP96_l"
      },
      "source": [
        "Para familiarizarnos con BERT, vamos a jugar con la tarea \"*Fill-Mask*\", cuyo objetivo es completar una oraci√≥n con algunas palabras, en los lugares marcados con `[MASK]`.\n",
        "\n",
        "El modelo de lenguaje predecir√° las palabras m√°s adecuadas para encajar en esos espacios en blanco, es decir, las m√°s probables dado el contexto, seg√∫n los patrones estad√≠sticos inferidos de los ejemplos de aprendizaje. Esto nos sirve para evaluar qu√© tan bien est√° modelando los textos."
      ],
      "id": "0IFLq1qP96_l"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "viJnXm9nzbSz"
      },
      "outputs": [],
      "source": [
        "# @markdown üîé\n",
        "# Usamos pipeline como funci√≥n auxiliar de alto nivel\n",
        "from transformers import pipeline\n",
        "\n",
        "fill_mask = pipeline(\n",
        "    task=\"fill-mask\",\n",
        "    model=\"dccuchile/bert-base-spanish-wwm-uncased\",\n",
        "    top_k=5\n",
        ")"
      ],
      "id": "viJnXm9nzbSz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8XrWlLOzyTO"
      },
      "outputs": [],
      "source": [
        "# @markdown üîé\n",
        "ejemplo = 'C√≥rdoba es una [MASK] de Argentina.'\n",
        "fill_mask(ejemplo)"
      ],
      "id": "n8XrWlLOzyTO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfc710ea"
      },
      "source": [
        "## Probamos un GPT para la tarea de generaci√≥n de texto\n",
        "\n",
        "En esta secci√≥n vamos a practicar con [GPT](https://en.wikipedia.org/wiki/Generative_pre-trained_transformer), un modelo de lenguaje generativo con una arquitectura basada en transformers.\n",
        "\n",
        "Vamos a jugar con la funci√≥n de generaci√≥n del modelo, que, dada una secuencia de palabras, predice la continuaci√≥n m√°s probable para la misma, seg√∫n los patrones inferidos en los ejemplos de aprendizaje."
      ],
      "id": "cfc710ea"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Y4F-eNCu0D3q"
      },
      "outputs": [],
      "source": [
        "# @markdown üîé\n",
        "# Usamos pipeline como funci√≥n auxiliar de alto nivel\n",
        "from transformers import pipeline\n",
        "\n",
        "text_gen = pipeline(\n",
        "    task=\"text-generation\",\n",
        "    model=\"gpt2\",\n",
        "    pad_token_id=50256\n",
        ")"
      ],
      "id": "Y4F-eNCu0D3q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAOGxhw10F1_"
      },
      "outputs": [],
      "source": [
        "# @markdown üîé\n",
        "ejemplo=\"My name is Lewis and I like to\"\n",
        "text_gen(ejemplo)"
      ],
      "id": "CAOGxhw10F1_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8958cf42"
      },
      "source": [
        "# 2 - Librer√≠as para modelos de lenguaje\n"
      ],
      "id": "8958cf42"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6038bd78"
      },
      "source": [
        "##  ¬øQu√© es Hugging Face ü§ó?\n",
        "\n",
        "- Una [comunidad colaborativa](https://huggingface.co/) especialmente enfocada en modelos de lenguaje y otros recursos de Inteligencia Artificial (IA).\n",
        "- Ofrece repositorios para disponibilizar [modelos](https://huggingface.co/models), [datasets](https://huggingface.co/datasets) y [demos](https://huggingface.co/spaces).\n",
        "- Adem√°s, ofrece varias librer√≠as orientadas a la IA, particularmente al Aprendizaje Profundo (*Deep Learning*), entre las que destacan:\n",
        "    - [`transformers`](https://huggingface.co/docs/transformers): La que veremos en esta charla, para todo lo relacionado a Procesamiento del Lenguaje Natural (PLN) con grandes modelos de lenguaje (*Large Language Models*, LLMs).\n",
        "    - [`datasets`](https://huggingface.co/docs/datasets): Una librer√≠a con funcionalidades para el tratamiento de los conjuntos de datos a utilizar para entrenar o ajustar los LLMs.\n",
        "    - [`tokenizers`](https://huggingface.co/docs/tokenizers): Una librer√≠a para el proceso de \"tokenizaci√≥n\", i.e. la divisi√≥n de texto de manera discreta en palabras o subpalabras.\n",
        "- Hugging Face no s√≥lo ofrece soluciones para PLN, sino tambi√©n para im√°genes, con librer√≠as como [`diffusers`](https://huggingface.co/docs/diffusers), para la generaci√≥n de im√°genes:\n",
        "    - Lectura recomendada: [The Illustrated Stable Diffusion](http://jalammar.github.io/illustrated-stable-diffusion/)"
      ],
      "id": "6038bd78"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25ad7d45"
      },
      "source": [
        "## ¬øC√≥mo empezar con Hugging Face ü§ó?\n",
        "\n",
        "- Primero se [crea una cuenta en la p√°gina](https://huggingface.co/join).\n",
        "- Luego podemos [crear modelos](https://huggingface.co/new) a trav√©s del men√∫ que se despliega de nuestro avatar.\n",
        "- Para poder subir el modelo personalizado que entrenaremos en esta notebook en tu cuenta de Hugging Face, necesitar√°s generar un token de acceso mediante los siguentes pasos:\n",
        "    1. **Acced√©** a la [secci√≥n de tokens de acceso](https://huggingface.co/settings/tokens) de tu perfil\n",
        "    <center><img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/User-Access-Token.png\" width=70%></center>\n",
        "    2. Cre√° un **nuevo token** de acceso con permiso de escritura.\n",
        "    <center><img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/hub/new-token.png\" width=60%></center>\n",
        "    3. **Listo!**. Ya ten√©s tu token preparado para poder subir tu modelo a la plataforma de Hugging Face ü§ó."
      ],
      "id": "25ad7d45"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkW7-sQW0bPf"
      },
      "source": [
        "# 3 - ¬øC√≥mo se entrenan los modelos de lenguaje?"
      ],
      "id": "AkW7-sQW0bPf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adb09645"
      },
      "source": [
        "En esta notebook **NO** vamos a entrenar completamente un LLM, porque los LLMs requieren de muchos datos y mucho c√≥mputo para ser entrenados:\n",
        "- Para **BERT**:\n",
        "    - El costo total estimado de entrenamiento del modelo fue de U\\$D 6912 (para su version *large*) y de U\\$D 500 (para su versi√≥n *base*).\n",
        "    - Mientras que la versi√≥n peque√±a (*base*) cuenta con 109M de par√°metros, su versi√≥n original (*large*) oscila en 334M, m√°s del triple.\n",
        "    - Su entrenamiento fue realizado sobre 3.3B de tokens (aproximadamente 20 GB de texto no comprimido).\n",
        "\n",
        "- Para **GPT-3**:\n",
        "    - Se estim√≥ un costo de entrenamiento cercano a los U\\$D 4.6 Millones.\n",
        "    - Disponible en ocho tama√±os, que van desde los 125M a los 175B par√°metros.\n",
        "    - Requiri√≥ de varias semanas de entrenamiento.\n",
        "    - El corpus reportado en el cual fue entrenado es aproximadamente 500B de palabras.\n",
        "    - Varios GPUS para entrenarlo y hardware especializado.\n",
        "\n",
        "Sin embargo, vamos a **entrenar parcialmente** un modelo de lenguaje, en concreto, vamos a adaptarlo a un dominio particular.\n"
      ],
      "id": "adb09645"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Diferencia entre pre-training y fine-tuning\n",
        "\n",
        "La distinci√≥n clave entre pre-training y fine-tuning se encuentra en las etapas del proceso de entrenamiento:\n",
        "\n",
        "* El **pre-training**, es la primera fase de entrenamiento al que se somete todo modelo LLM, y requiere de una enorme cantidad de textos gen√©ricos, como se ha descrito en el apartado anterior.\n",
        "\n",
        "* Una vez finalizado este proceso inicial de entrenamiento, se obtiene un modelo gen√©rico capaz de realizar predicciones gen√©ricas sobre patrones textuales, pero sin especializaci√≥n en ninguna tareas espec√≠ficas.\n",
        "\n",
        "* Si deseamos adaptar este modelo gen√©rico para que desempe√±e una tarea espec√≠fica con un alto rendimiento (e.g.: *Text Clasification*, *Sentiment analysis*, *Question Answering*, *Information Extraction*, etc.), se lleva a cabo una segunda etapa de entrenamiento conocida como **fine-tuning**.\n",
        "\n",
        "<center>\n",
        "<!-- <img src=\"https://serokell.io/files/7i/7iyrq1z5.Inside_ChatGPT_pic1.png\" width=80%>-->\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:951/0*R31A71UjHM8R8Pps.png\" width=80%>\n",
        "</center>\n",
        "<right> fuente: https://medium.com/mantisnlp/supervised-fine-tuning-customizing-llms-a2c1edbf22c3\n",
        "</right>\n",
        "\n",
        "Este entrenamiento espec√≠fico requiere de menos ejemplos de entrenamiento y menos c√°lculo, ya que s√≥lo modifica ligeramente el modelo ya entrenado. En este proceso, existen var√≠as formas en como se \"modifica\" el modelo pre-entrenado durante esta fase: se pueden modificar las √∫ltimas capas, a√±adir capas a la red pre-entrenada, y otras variantes. En esta notebook vamos a trabajar con una aproximaci√≥n sencilla, pero existen m√∫ltiples librer√≠as en Huggingface que implementan funcionalidades para llevar adelante difrentes tipos de *fine-tuning*, como por ejemplo la popular [LoRA](https://www.databricks.com/blog/efficient-fine-tuning-lora-guide-llms).\n",
        "\n",
        "<!--<center>\n",
        "<img src=\"https://media.licdn.com/dms/image/D5612AQEe2e_DJ51f2g/article-inline_image-shrink_1000_1488/0/1687324002269?e=1699488000&v=beta&t=vWDbM2RYNKa9tv5--w6Iub7YRRGkjld-s7U6VDd_7_Q\" width=80%>\n",
        "\n",
        "</center>\n",
        "<right> fuente: https://www.linkedin.com/pulse/beginners-guide-fine-tuning-large-language-models-vaidheeswaran\n",
        "</right>-->"
      ],
      "metadata": {
        "id": "ryVETkJgWtT3"
      },
      "id": "ryVETkJgWtT3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Domain Adaptation*\n",
        "\n",
        "Mientras que *fine-tuning* se centra en ajustar un modelo de lenguaje *pre-entrenado* para realizar tareas espec√≠ficas, la adaptaci√≥n de dominio se enfoca en hacer que el modelo sea m√°s efectivo en un dominio de datos particular.\n",
        "\n",
        "En caso de que tus datos de entrenamiento pertenezcan a un determinado tema espec√≠fico (e.g.: leyes, medicina, inform√°tica, etc.) o un estilo espec√≠fico (e.g.: acad√©mico, infantil, publicitario, etc.), y difieran substancialmente del corpus est√°ndar en el cual fue entrenado inicialmente el LLM, podemos pensar diferentes opciones para incorparar este nuevo conocimiento:\n",
        "\n",
        "\n",
        "1. **Entrenamiento desde cero:** Este enfoque implica entrenar desde cero (*from scratch*) un nuevo modelo de lenguaje con textos del dominio de inter√©s. Sin embargo, no es recomendable para el p√∫blico en general, dada la gran cantidad de recursos computacionales, horas de procesamiento y textos de entrenamiento necesarios para lograr un rendimiento comparable a los modelos estado del arte (modelos *state-of-the-art, SOTA*).\n",
        "2.  **Uso de modelos disponibles:** Se aprovechan modelos disponibles p√∫blicamente, espec√≠ficos para el dominio de inter√©s (e.g: [LegalBERT](https://arxiv.org/abs/2010.02559), [FinBERT](https://arxiv.org/abs/1908.10063) y [BioBERT](https://arxiv.org/abs/1901.08746); todos disponibles en Hugging Face ü§ó de manera gratuita.)\n",
        "3. **Adaptaci√≥n de modelos pre-entrenados**: Esta aproximaci√≥n, tambien conocida en la literatura como *'further pre-training'*, *'inter-training'*, *'continued pre-training'* o *'domain-adaptation'*, implica tomar un modelo de lenguaje pre-entrenado para un dominio cualquiera y, aprovechando todo el conocimiento y las representaciones ya aprendidas, **continuar su entrenamiento sobre el conjunto de datos especializados o personalizados**. Esta t√©cnica permite alcanzar muy buenos resultados, utilizando menos recursos computacionales, horas y datos de entrenamiento.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*4eNaH6y0dSsaxtTQW0tgHQ.png\" width=80%>\n",
        "</center>\n",
        "<right> fuente: https://medium.com/@shankar.arunp/training-bert-from-scratch-on-your-custom-domain-data-a-step-by-step-guide-with-amazon-25fcbee4316a\n",
        "</right>"
      ],
      "metadata": {
        "id": "NKBq_dr38Kld"
      },
      "id": "NKBq_dr38Kld"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWA7IwMyuQcG"
      },
      "source": [
        "# 4 - Vamos a personalizar un modelo!"
      ],
      "id": "zWA7IwMyuQcG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv2KNF96xlXQ"
      },
      "source": [
        "## 4.1 - ¬øC√≥mo personalizar un modelo BERT?\n"
      ],
      "id": "zv2KNF96xlXQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHSuvnM21DmM"
      },
      "source": [
        "Tanto para el entrenamiento inicial (*pre-training*) como para la adaptaci√≥n de dominio mediante un entrenamiento intermedio (*inter-training*), el modelo debe ser re-entrenado utilizando tareas auto-supervisadas, ya sea la tarea de **Masked Language Modeling (MLM)**, o una combinaci√≥n entre **(MLM)** y **Next Sentence Prediction (NSP)**.\n",
        "\n",
        "### Masked Language Modeling (MLM)\n",
        "> Consiste en enmascarar (ocultar) palabras aleatorias en cada oraci√≥n o frase de entrada, y entrenar el modelo para que aprenda a predecirlas bas√°ndose en el contexto circundante (palabras vecinas). Durante el entrenamiento, alrededor del **15%** de las palabras se seleccionan al azar y se enmascaran, reemplaz√°ndolas con el token especial **[MASK]**. De esta forma, el modelo infiere patrones de relaciones entre palabras.\n",
        "<center>\n",
        "<img src=\"http://jalammar.github.io/images/BERT-language-modeling-masked-lm.png\" width=65%>\n",
        "</center>\n",
        "\n",
        "### Next Sentence Prediction (NSP)\n",
        "> Aunque no obligatorio, es otro componente importante en el entrenamiento de BERT. A partir de un texto considerado como una secuencia de oraciones, se generan ejemplos de entrenamiento consistentes en pares de oraciones aleatorios. El modelo tiene que aprender a identificar si una oraci√≥n sigue a otra en el texto original. De esta forma, el modelo infiere patrones de relaciones entre oraciones.\n",
        "\n",
        "<center>\n",
        "<img src=\"http://jalammar.github.io/images/bert-next-sentence-prediction.png\" width=65%>\n",
        "</center>\n",
        "\n",
        "En esta notebook **realizaremos el ajuste de dominio mediante la tarea de MLM** utilizando la clase [**BertForMaskedLM**](https://huggingface.co/docs/transformers/v4.32.1/en/model_doc/bert#transformers.BertForMaskedLM) (modelo BERT con un bloque superior extra que posibilita el `modelado del lenguaje enmascarado`), ofrecida por la biblioteca [**transformer**](https://github.com/huggingface/transformers) de Hugging Face ü§ó.\n",
        "\n",
        "* Se utilizar√°n diferentes datasets especializados (tanto en espa√±ol como en ingl√©s).\n",
        "* Utilizaremos como modelo pre-entrenado  [bert-base-uncased](https://huggingface.co/bert-base-uncased) para realizar la adaptaci√≥n en los datasets en ingl√©s, y [dccuchile/bert-base-spanish-wwm-uncased](https://huggingface.co/dccuchile/bert-base-spanish-wwm-uncased) para los correspondientes en espa√±ol.\n"
      ],
      "id": "qHSuvnM21DmM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHLX6wTQml1n"
      },
      "source": [
        "### Carga de datasets"
      ],
      "id": "qHLX6wTQml1n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfgry7ccvHUi"
      },
      "source": [
        "* Utilizaremos la librer√≠a `datasets` de HuggingFace para cargar cada uno de los corpus seleccionados.\n",
        "* Para la personalizaci√≥n de BERT, tenemos un total de 4 conjuntos de datos, 3 de ellos en espa√±ol y 1 en Ingl√©s:\n",
        "    * Peppa Pig (es):\n",
        "      * ‚âà 3k muestras.\n",
        "      * Extra√≠do de subt√≠tulos de 77 episodios.\n",
        "    * Martin Fierro (es):\n",
        "      * ‚âà 2k muestras.\n",
        "      * Extra√≠do del libro completo de Jos√© Hern√°ndez\n",
        "    * Preguntas de no videntes (en):\n",
        "      * ‚âà 33k muestras.\n",
        "      * Generado a partir de preguntas visuales realizadas sobre im√°genes tomadas por personas con discapacidades visuales durante la ejecuci√≥n de sus tareas cotidianas. *(click [aqui](https://vizwiz.org/tasks-and-datasets/vqa/) para mas informaci√≥n sobre este dataset)*\n",
        "    * Rese√±as de Vinos (es):\n",
        "      * ‚âà 130k muestras.\n",
        "      * Extra√≠do de descripciones de vinos de todo el mundo.\n",
        "* A continuaci√≥n, seleccionen de la lista desplegable el dataset que mas nos interese.\n",
        "* En `max_samples`, elijan un l√≠mite m√°ximo de datos para acotar el c√≥mputo necesario.\n",
        "* Autom√°ticamente el siguiente c√≥digo dividir√° el dataset elegido en dos partes:\n",
        "    * El 80% como conjunto de entrenamiento.\n",
        "    * El 20% como conjunto de test.\n"
      ],
      "id": "rfgry7ccvHUi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSX-6B_qguzS"
      },
      "outputs": [],
      "source": [
        "# @markdown ‚ùó\n",
        "# @title  { run: \"auto\" }\n",
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "# Fijaci√≥n de semilla para reproducibilidad de resultados\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Recolecci√≥n de par√°metros de formulario\n",
        "DATASET_NAME = \"Peppa Pig (es)\" # @param [\"Referencias de Vinos (es)\", \"Preguntas de no videntes (en)\", \"Martin Fierro (es)\", \"Peppa Pig (es)\"]\n",
        "max_samples = 30000 # @param {type:\"number\"}\n",
        "name_to_file = {\n",
        "    'Preguntas de no videntes (en)' : \"vizwiz.csv\",\n",
        "    'Referencias de Vinos (es)'     : \"wines_es.csv\",\n",
        "    'Martin Fierro (es)'            : \"martin_fierro.csv\",\n",
        "    'Peppa Pig (es)'                : \"peppa_pig.csv\",\n",
        "}\n",
        "\n",
        "# Carga de conjunto de datos\n",
        "bert_ds = load_dataset(\n",
        "    path=DATASETS_PATH,\n",
        "    data_files={'all_data': name_to_file[DATASET_NAME]},\n",
        ")\n",
        "\n",
        "# Divisi√≥n de conjunto de datos en subconjuntos de entrenamiento y testeto\n",
        "total_size = min(max_samples, len(bert_ds['all_data']))\n",
        "val_size = int(total_size *.2)\n",
        "train_size = total_size - val_size\n",
        "\n",
        "bert_ds = bert_ds[\"all_data\"].train_test_split(\n",
        "    train_size=train_size,\n",
        "    test_size=val_size,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "print(f\"* Informaci√≥n de dataset '{DATASET_NAME}':\\n---\")\n",
        "bert_ds"
      ],
      "id": "pSX-6B_qguzS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlGtTeKuqXhY"
      },
      "outputs": [],
      "source": [
        "# @markdown üîé\n",
        "# Vizualizaci√≥n de primeros 15 ejemplos del dataset\n",
        "for sample in bert_ds['train']['samples'][:15]:\n",
        "    print(f\">> {sample}\")"
      ],
      "id": "WlGtTeKuqXhY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6_bKfAfxlX4"
      },
      "source": [
        "### Tokenizaci√≥n de datos"
      ],
      "id": "A6_bKfAfxlX4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzKg_zDnw-eN"
      },
      "source": [
        "\n",
        "- La tokenizaci√≥n es un paso de pre-procesamiento esencial cuando se utiliza BERT u otro LLM.\n",
        "- BERT procesa el texto en forma de tokens, que son elementos individuales del texto de entrada, como palabras, signos de puntuaci√≥n o tokens especiales como **[CLS]**, **[SEP]** , **[PAD]** , **[UNK]** , etc.\n",
        "- Recuerde utilizar el modelo `bert-base-uncased` como modelo base para los datasets en idioma ingl√©s, y `dccuchile/bert-base-spanish-wwm-uncased` para los datasets en espa√±ol."
      ],
      "id": "kzKg_zDnw-eN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sljDH7pDxlX4",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# @markdown ‚ùó\n",
        "# Iniciaci√≥n de tokenizador\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "MODEL_CHECKPOINT = \"dccuchile/bert-base-spanish-wwm-uncased\" # @param [\"bert-base-uncased\",\"dccuchile/bert-base-spanish-wwm-uncased\"]\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_CHECKPOINT, TOKENIZERS_PARALLELISM=False)"
      ],
      "id": "sljDH7pDxlX4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WG5eUd-23Nna"
      },
      "outputs": [],
      "source": [
        "# @markdown üîé\n",
        "# Tokenizaci√≥n de ejemplo de prueba\n",
        "samples = bert_ds['train']['samples'][:5]\n",
        "\n",
        "for ith, sample in enumerate(samples):\n",
        "    token_ids = tokenizer(sample)['input_ids']\n",
        "    token_str = [tokenizer.decode([tk_id]) for tk_id in token_ids]\n",
        "    print(f\"{sample}\")\n",
        "    print(f\"{token_str}\\n\")"
      ],
      "id": "WG5eUd-23Nna"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJKX4o_wyR0P"
      },
      "outputs": [],
      "source": [
        "# @markdown üîé\n",
        "# Visualizaci√≥n de 'tokes especiales' utilizados por tokenizador\n",
        "for name, tk in tokenizer.special_tokens_map.items():\n",
        "    print(f\"{name}. Token: {tk}; Token_id: {tokenizer.vocab[tk]}\")"
      ],
      "id": "YJKX4o_wyR0P"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Q1jy5PUJjUN"
      },
      "source": [
        "* Dado que entrenaremos un modelo de BERT con un conjunto de datos que tienen una longitud variable, es fundamental aplicar el proceso de tokenizaci√≥n y el relleno (padding) adecuados a nuestros datos. Esto permite que todas las secuencias tengan la misma longitud fija, garantizando un procesamiento uniforme y eficiente de los datos durante el entrenamiento y la inferencia.\n",
        "* A continuaci√≥n realizaremos un histograma de la cantidad de tokens de cada ejemplo, y utilizaremos esa informaci√≥n para realizar posteriormente la tokenizaci√≥n del dataset completo."
      ],
      "id": "1Q1jy5PUJjUN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jo2jc6IM1y9x"
      },
      "outputs": [],
      "source": [
        "# @markdown ‚ùó\n",
        "# Generaci√≥n de histograma de n√∫mero de tokens por ejemplos\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# C√°lculo de n√∫mero de tokens por ejemplos\n",
        "def count_tokens_fn(batch):\n",
        "    tokenized_batch = tokenizer(batch['samples'])\n",
        "    tokenized_batch['count'] = [len(tks) for tks in tokenized_batch['input_ids']]\n",
        "    return tokenized_batch\n",
        "\n",
        "result = bert_ds.map(\n",
        "    function=count_tokens_fn,\n",
        "    batched=True\n",
        ")\n",
        "\n",
        "num_of_tokens_list = result['train']['count'] + result['test']['count']\n",
        "\n",
        "# Generaci√≥n de histograma\n",
        "plt.hist(num_of_tokens_list, bins=35, edgecolor='k')\n",
        "plt.xlabel('N√∫mero de Tokens')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.title('N√∫mero de Tokens por Ejemplo')\n",
        "plt.show()\n",
        "\n",
        "# C√°lculo de percentiles (e.g., 25th, 50th, and 75th percentiles)\n",
        "percentiles = np.percentile(num_of_tokens_list, [25, 50, 75])\n",
        "\n",
        "print(f\"Total de ejemplos: {len(num_of_tokens_list)}\")\n",
        "print(f\"Percentil 25: {percentiles[0]}\")\n",
        "print(f\"Percentil 50 (Mediana): {percentiles[1]}\")\n",
        "print(f\"Percentile 75: {percentiles[2]}\")\n",
        "print(f\"Max: {np.max(num_of_tokens_list)}\")"
      ],
      "id": "jo2jc6IM1y9x"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0CPWdsYIFZi"
      },
      "source": [
        "- La funci√≥n auxiliar `tokenize_data_fn` servir√° para tokenizar y codificar el conjunto completo de datos de manera eficiente mediante el [m√©todo `map`](https://huggingface.co/docs/datasets/about_map_batch).\n",
        "- Lo que devuelve es un nuevo dataset cuyos tokens estar√°n convertidos en:\n",
        "    - √≠ndices del vocabulario (*input_ids*),\n",
        "    - mascaras de atenci√≥n [(*attention_mask*)](https://huggingface.co/docs/transformers/glossary#attention-mask),\n",
        "    - tipos de tokens [(*token_type_ids*)](https://huggingface.co/docs/transformers/glossary#token-type-ids),\n",
        "    - y etiquetas (*labels*), los cuales ser√°n untilizados como `Ground True` en la etapa de entrenamiento.\n",
        "- `MAX_TOKEN_LENGTH`: Indica el m√°ximo n√∫mero de tokens a utilizar por data. Debemos aumentarlo cuando nuestros conjuntos de datos son m√°s largos. Una estrategia com√∫n es realizar un histograma y quedarnos con el valor del percentil 75% del largo de nuestros datos. Tambi√©n podemos utilizar el n√∫mero de tokens de la seccuencia mas larga si se dispone de capacidad de c√≥mputo suficiente."
      ],
      "id": "F0CPWdsYIFZi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDyitCyOySe2"
      },
      "outputs": [],
      "source": [
        "# @markdown ‚ùó\n",
        "# Tokenicaci√≥n de conjunto de datos completo\n",
        "\n",
        "# N√∫mero m√°ximo de tokens a utilizar\n",
        "MAX_TOKEN_LENGTH = 33 # @param {type:\"number\"}\n",
        "\n",
        "def tokenize_data_fn(batch):\n",
        "    tokenized_sample = tokenizer(\n",
        "        batch['samples'],\n",
        "        max_length=MAX_TOKEN_LENGTH,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    tokenized_sample[\"labels\"] = tokenized_sample['input_ids'].clone()\n",
        "    return tokenized_sample\n",
        "\n",
        "tokenized_bert_ds = bert_ds.map(\n",
        "    function=tokenize_data_fn,\n",
        "    batched=True,\n",
        "    remove_columns=[\"samples\"]\n",
        ")\n",
        "\n",
        "print(tokenized_bert_ds)"
      ],
      "id": "JDyitCyOySe2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duPj1x54EQB5"
      },
      "outputs": [],
      "source": [
        "# @markdown üîé\n",
        "# Visualizaci√≥n de proceso de tokenizaci√≥n para el primer ejemplo del conjunto de datos\n",
        "sample = tokenized_bert_ds[\"train\"][0]\n",
        "\n",
        "print(f\"- input_ids:        {sample['input_ids']}\")\n",
        "print(f\"- attention_mask:   {sample['attention_mask']}\")\n",
        "print(f\"- token_type_ids:   {sample['token_type_ids']}\")\n",
        "print(f\"- labels:           {sample['labels']}\")"
      ],
      "id": "duPj1x54EQB5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdRVPRVdHG0c"
      },
      "source": [
        "### Enmascarado Aleatorio"
      ],
      "id": "jdRVPRVdHG0c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_ShVU5yQIth"
      },
      "source": [
        "> Este m√©todo se encarga de realizar el enmascaramiento aleatorio y formatear los datos de entrenamiento de manera adecuada, asegurando que las secuencias de entrada tengan la longitud correcta y que las m√°scaras de atenci√≥n se apliquen correctamente.\n",
        "\n",
        "* Para implementar este proceso de manera sencilla, utilizaremos el m√©todo [DataCollatorForLanguageModeling](https://huggingface.co/docs/transformers/v4.32.1/en/main_classes/data_collator#transformers.DataCollatorForLanguageModeling) proporcionado por la biblioteca HuggingFace.\n",
        "\n",
        "* Como se podr√° observar en el siguente ejemplo, es com√∫n utilizar un valor especial como **-100** en la salida de las etiquetas (*labels*) para indicar la posici√≥n de los tokens que se **IGNORAN** en el c√°lculo de la funci√≥n de p√©rdida llevada a cabo durante el entrenamiento."
      ],
      "id": "h_ShVU5yQIth"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWHvQlnUHBWb"
      },
      "outputs": [],
      "source": [
        "# @markdown ‚ùó\n",
        "import torch, random\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "\n",
        "data_collate_fn = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm_probability=0.15\n",
        ")"
      ],
      "id": "dWHvQlnUHBWb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9xeuMP5H1aq"
      },
      "outputs": [],
      "source": [
        "# @markdown üîé\n",
        "# Visualizacion de proceso de 'enmascarado aleatorio' de tokens\n",
        "seed = random.randint(0,100)\n",
        "samples = [tokenized_bert_ds['train'][i] for i in range(3)]\n",
        "\n",
        "print(\"DataCollator Outputs\")\n",
        "torch.manual_seed(seed)\n",
        "print(\"--- Tokens:\")\n",
        "for sample in data_collate_fn(samples)['input_ids']:\n",
        "    print(f\">> {[tokenizer.decode([tk]) for tk in sample]}'\")\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "print(\"\\n--- 'input_ids':\")\n",
        "for sample in data_collate_fn(samples)['input_ids']:\n",
        "    print(f\">> {sample.tolist()}'\")\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "print(\"\\n--- 'labels':\")\n",
        "for sample in data_collate_fn(samples)['labels']:\n",
        "    print(f\">> {sample.tolist()}\")"
      ],
      "id": "G9xeuMP5H1aq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiEflsvRxlX1"
      },
      "source": [
        "### Probando el Modelo Base"
      ],
      "id": "XiEflsvRxlX1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSwnO4nXvWU7"
      },
      "source": [
        "- Antes de ajustar el modelo a nuestro conjunto de datos seleccionados, veremos c√≥mo se desenvuelve en la tarea de *fill-mask* **antes de la personalizaci√≥n**.\n",
        "\n",
        "- Para ello, escriba una frase muy caracter√≠stica del dominio al que se quiere adaptar, y enmascare alguna de sus palabras utilizando el token `[MASK]`.\n"
      ],
      "id": "tSwnO4nXvWU7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NL3CDtZQxlX2"
      },
      "outputs": [],
      "source": [
        "# @markdown üîé\n",
        "# Ejemplo para espa√±ol, pensando en adaptar el modelo a Peppa Pig\n",
        "# Usamos pipeline como funci√≥n auxiliar de alto nivel\n",
        "from transformers import pipeline\n",
        "\n",
        "fill_mask = pipeline(\n",
        "    task=\"fill-mask\",\n",
        "    model=\"dccuchile/bert-base-spanish-wwm-uncased\",\n",
        "    top_k=5\n",
        ")\n",
        "\n",
        "ejemplo = 'A Peppa le encanta saltar en los [MASK] de barro'\n",
        "fill_mask(ejemplo)"
      ],
      "id": "NL3CDtZQxlX2"
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown üîé\n",
        "# Ejemplo para ingl√©s, pensando en adaptar el modelo a VizWiz\n",
        "# Usamos pipeline como funci√≥n auxiliar de alto nivel\n",
        "from transformers import pipeline\n",
        "\n",
        "fill_mask = pipeline(\n",
        "    task=\"fill-mask\",\n",
        "    model=\"bert-base-uncased\",\n",
        "    top_k=5\n",
        ")\n",
        "\n",
        "ejemplo = \"Can you [MASK] me the model on the back of the iPhone?\"\n",
        "fill_mask(ejemplo)"
      ],
      "metadata": {
        "id": "-RIWajZ9AESD"
      },
      "id": "-RIWajZ9AESD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dS8OpI86xlX6"
      },
      "source": [
        "### Entrenamiento para adaptaci√≥n"
      ],
      "id": "dS8OpI86xlX6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Una vez definido el conjunto de datos, pasamos a la parte m√°s intensa computacionalmente, el entrenamiento.\n",
        "- Podemos decidir guardar el modelo localmente o hacer un backup de cada √©poca del modelo en Hugging Face.\n",
        "- Definimos las propiedades del entrenamiento mediante [`TrainingArguments`](https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/trainer#transformers.TrainingArguments).\n",
        "- Definimos el entrenamiento del modelo mediante [`Trainer`](https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/trainer#transformers.Trainer).\n",
        "    \n",
        "> <u>Detalles de par√°metros a configurar</u>:\n",
        "1.   ***epochs***: Cantidad de epochs (una epoch es una pasada completa del dataset para el algoritmo de entrenamiento)\n",
        "2.  ***batch_size***: Cantidad de datos procesados por iteraci√≥n antes de actualizar el modelo (aumentar este n√∫mero mejora las estimaciones de cada iteraci√≥n ya que ser√° una muestra m√°s representativa del dataset en general, pero requerir√° m√°s memoria)\n",
        "3.  ***learning_rate***:  Tama√±o del 'paso' en la actualizaci√≥n del modelo en cada iteraci√≥n mientras avanza hacia un m√≠nimo de la funci√≥n de p√©rdida.\n",
        "\n",
        "**Nota**: El valor de estos par√°metros determinar√° el tiempo y la cantidad de c√°lculo requerido para poder realizar el entrenamiento del modelo. El mismo, puede ir desde unos segundos hasta varios minutos, dependiendo de los par√°metros configurados y el poder de c√≥mputo disponible.\n"
      ],
      "metadata": {
        "id": "8rwbTbV6YqfY"
      },
      "id": "8rwbTbV6YqfY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3NP1ORPxlX7"
      },
      "outputs": [],
      "source": [
        "# @markdown ‚ùó\n",
        "from transformers import TrainingArguments, Trainer, BertForMaskedLM\n",
        "\n",
        "# Eliminaci√≥n de checkpoints anteriores\n",
        "!rm -r \"$CUSTOM_MODEL_CHECKPOINT\"\n",
        "\n",
        "# Configuraci√≥n de hiperpar√°metros\n",
        "MODEL_CHECKPOINT = \"dccuchile/bert-base-spanish-wwm-uncased\" # @param [\"dccuchile/bert-base-spanish-wwm-uncased\", \"bert-base-uncased\"]\n",
        "BATCH_SIZE = 64 # @param {type:\"slider\", min:8, max:64, step:8}\n",
        "LEARNING_RATE = 2e-5 # @param {type:\"number\"}\n",
        "EPOCHS = 5 # @param {type:\"slider\", min:3, max:15, step:1}\n",
        "LOGGING_STEPS = len(tokenized_bert_ds[\"train\"]) // BATCH_SIZE\n",
        "CUSTOM_MODEL_CHECKPOINT = \"bert_adaptation_\" + DATASET_NAME.replace(\" \", \"_\")[:-5].lower()\n",
        "\n",
        "# Configuraci√≥n de entrenamiento\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=CUSTOM_MODEL_CHECKPOINT,\n",
        "    overwrite_output_dir=True,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    num_train_epochs=EPOCHS,\n",
        "    optim='adamw_torch',\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    weight_decay=0.01,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    push_to_hub=False,\n",
        "    fp16=True,\n",
        "    logging_steps=LOGGING_STEPS,\n",
        "    report_to=\"none\",\n",
        "    save_strategy=\"no\"\n",
        ")\n",
        "\n",
        "# Instanciaci√≥n de modelo\n",
        "model = BertForMaskedLM.from_pretrained(MODEL_CHECKPOINT)\n",
        "\n",
        "# Instanciaci√≥n de clase Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_bert_ds[\"train\"],\n",
        "    eval_dataset=tokenized_bert_ds[\"test\"],\n",
        "    data_collator=data_collate_fn,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "trainer.args._n_gpu = 1"
      ],
      "id": "c3NP1ORPxlX7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Antes de comenzar el entrenamiento calcularemos la [**Perplexity**](https://huggingface.co/docs/transformers/perplexity) del modelo de lenguaje.\n",
        "\n",
        "> La `Perplexity` es una m√©trica que nos permite evaluar cu√°nta incertidumbre tiene un modelo cuando tiene que predecir palabras en un conjunto de prueba determinado. La misma, ayuda a medir qu√© tan bien conoce el modelo el lenguaje, y cu√°n coherentes ser√°n sus predicciones. En general, una perplejidad m√°s baja indicar√° que el modelo genera textos que claramente pertenecen al lenguaje.\n",
        "<center>\n",
        "<img src=\"https://thegradient.pub/content/images/size/w1600/2020/04/xkcd_entropy-2.png\" width=50%>\n",
        "</center>\n",
        "fuente: https://thegradient.pub/understanding-evaluation-metrics-for-language-models/\n",
        "\n",
        "Si queremos evaluar qu√© tanto se adapta un modelo a un dominio determinado, podemos ver la perplejidad que tiene el modelo para las tareas de completar palabras (MLM) o generaci√≥n de texto en oraciones del dominio de inter√©s, ya sea un conjunto de oraciones que nos interesen particularmente (un *benchmark* o *testbed*) o un corpus representativo del dominio en general.\n",
        "\n",
        "* Luego del entrenamiento, estimaremos la `perplexity` del modelo y compararemos con los valores obtenidos previos al mismo."
      ],
      "metadata": {
        "id": "CcqCvC7kjC0C"
      },
      "id": "CcqCvC7kjC0C"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIhYYrmgO6ac"
      },
      "outputs": [],
      "source": [
        "# @markdown  üîé\n",
        "import math\n",
        "\n",
        "# Fijamos semilla para reproducibilidad de resultados\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Estimaci√≥n de perplexity previa a entrenamieto\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
      ],
      "id": "VIhYYrmgO6ac"
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown ‚ùó‚è≥\n",
        "# Inicio de entrenamiento\n",
        "trainer.train()\n",
        "\n",
        "# Guardado de entrenamiento\n",
        "trainer.save_model(CUSTOM_MODEL_CHECKPOINT)"
      ],
      "metadata": {
        "id": "ypbXFA8TaCeh"
      },
      "id": "ypbXFA8TaCeh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown üîé\n",
        "# Fijamos semilla para reproducibilidad de resultados\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Estimaci√≥n de perplexity posterior a entrenamiento\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\">>> Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
      ],
      "metadata": {
        "id": "uWAZ_qTzb_AA"
      },
      "id": "uWAZ_qTzb_AA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOUDT3zYxlX7"
      },
      "source": [
        "\n",
        "### Probando el Modelo Adaptado\n",
        "\n",
        "- Ahora que tenemos el modelo entrenado con el dataset espec√≠fico, la pregunta es, ¬øC√≥mo se comportar√°?\n",
        "- Para ello volvemos a hacer la prueba anterior utilizando la tarea de *fill-mask*, quiz√°s esta vez con mejores resultados.\n",
        "- Para que los resultados sean mas f√°ciles de comparar, la funci√≥n `compare_models()` ser√° la encargada de procesar y retornar, para cada frase de ejemplo ingresada, un ranking comparativo de las predicciones realizadas entre el nuevo modelo adaptado y el modelo base original."
      ],
      "id": "aOUDT3zYxlX7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvR2XoSGxlX7"
      },
      "outputs": [],
      "source": [
        "# @markdown ‚ùó\n",
        "import os\n",
        "import transformers\n",
        "from typing import List\n",
        "from tabulate import tabulate\n",
        "from transformers import pipeline\n",
        "\n",
        "# Funci√≥n auxiliar para comparaci√≥n de predicciones de modelos\n",
        "def compare_models(\n",
        "    custom_model: transformers.pipelines.fill_mask.FillMaskPipeline,\n",
        "    base_model: transformers.pipelines.fill_mask.FillMaskPipeline,\n",
        "    sentences: List[str],\n",
        "    top_k=5\n",
        ") -> None:\n",
        "\n",
        "    headers = ['Sent','Custom Bert', '(%)', 'Base Bert', '(%)']\n",
        "    rows = []\n",
        "    for sent in sentences:\n",
        "        rows.append([sent, '', '', '', ''])\n",
        "\n",
        "        c_out = custom_model(sent)\n",
        "        o_out = base_model(sent)\n",
        "\n",
        "        c_tokens = [(i['token_str'], str(round(i['score']*100,1))+\"%\") for i in c_out]\n",
        "        o_tokens = [(i['token_str'], str(round(i['score']*100,1))+\"%\") for i in o_out]\n",
        "\n",
        "        for (p1,s1), (p2,s2) in zip(c_tokens, o_tokens):\n",
        "            rows.append(['', p1, s1, p2, s2])\n",
        "\n",
        "    table = tabulate(rows, headers=headers, tablefmt=\"text\", numalign=\"center\")\n",
        "    print(table, \"\\n\")\n",
        "\n",
        "# Instanciaci√≥n de modelo personalizado y modelo base\n",
        "base_model = pipeline(task=\"fill-mask\", model=MODEL_CHECKPOINT)\n",
        "custom_model = pipeline(task=\"fill-mask\", model=CUSTOM_MODEL_CHECKPOINT)"
      ],
      "id": "VvR2XoSGxlX7"
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown ‚ùó\n",
        "\n",
        "# Conjunto de ejemplos de prueba\n",
        "vizwiz_test_examples = [\n",
        "    \"can you tell me the title of the book? [MASK].\",\n",
        "    \"please [MASK] this shirt\",\n",
        "    \"what [MASK] is this?\",\n",
        "    \"[MASK] can you tell me what is this?\",\n",
        "    \"how clear is this [MASK]?\",\n",
        "    \"is the floor [MASK]?\",\n",
        "    \"the microwave is [MASK]?.\"\n",
        "]\n",
        "\n",
        "vinos_test_examples = [\n",
        "    \"Este [MASK] argentino de altura es una verdadera\",\n",
        "    \"Con un color profundo e [MASK]\",\n",
        "    \"Los sabores de [MASK] persisten\",\n",
        "    \"Hecho 100% de [MASK]\",\n",
        "    \"El sabor fue [MASK]\",\n",
        "    \"Con su [MASK] mezcla de minerales\",\n",
        "    \"Por primera vez en [MASK],\",\n",
        "    \"Brazamora de [MASK] bonito\"\n",
        "]\n",
        "\n",
        "martin_fierro_test_examples = [\n",
        "    \"En los campos de la [MASK] extensa\",\n",
        "    \"donde el viento y el sol se [MASK]\",\n",
        "    \"cabalgo firme con mi [MASK]\",\n",
        "    \"bajo el cielo de [MASK] risue√±o\",\n",
        "\n",
        "    \"Con mi [MASK] y mi lazo\",\n",
        "    \"enfrento a la [MASK] con valor\",\n",
        "    \"bati√©ndome siempre a mi [MASK]\",\n",
        "    \"en este ancho y rudo [MASK]\",\n",
        "\n",
        "    \"As√≠ cabalgo con alma [MASK]\",\n",
        "    \"como otros en su [MASK]\",\n",
        "    \"defendiendo mi [MASK] y mi gente\",\n",
        "    \"en esta tierra que [MASK] sin cesar\",\n",
        "\n",
        "    \"Con [MASK] al cinto, firme y diestro\",\n",
        "    \"Enfrento [MASK], firme como el resto\",\n",
        "    \"Mate en mano, bajo el cielo [MASK]\",\n",
        "    \"Mi coraje y mi [MASK], jam√°s han claudicado.\"\n",
        "]\n",
        "\n",
        "peppa_pig_test_examples = [\n",
        "    \"[MASK], puedes decir dinosarurio?\",\n",
        "    \"¬°Hola, soy Peppa [MASK]!\",\n",
        "    \"Hoy es un d√≠a [MASK] para un picnic.\",\n",
        "    \"George tiene un [MASK] muy querido.\",\n",
        "    \"El sol brilla en el [MASK] del jard√≠n.\",\n",
        "    \"Peppa y George juegan en el [MASK].\",\n",
        "    \"Mam√° Pig prepara [MASK] deliciosos.\",\n",
        "    \"Vamos al [MASK] para montar en bicicleta.\",\n",
        "    \"El [MASK] est√° lleno de flores hermosas.\",\n",
        "    \"Peppa y sus amigos tienen [MASK] en el parque.\"\n",
        "]\n",
        "\n",
        "# Moficar 'sentences' acorde al conjunto de datos utilizado para la personalizaci√≥n\n",
        "compare_models(\n",
        "    custom_model=custom_model,\n",
        "    base_model=base_model,\n",
        "    sentences=peppa_pig_test_examples\n",
        ")"
      ],
      "metadata": {
        "id": "JTAxPD4qd-ZG"
      },
      "id": "JTAxPD4qd-ZG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Subi tu modelo a Hugging Face  ü§ó"
      ],
      "metadata": {
        "id": "AlaINEj1o2LR"
      },
      "id": "AlaINEj1o2LR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Recorda generar tu **token de acceso** siguendo las instrucciones de la [Secci√≥n 2](#Librer√≠as-para-modelos-de-lenguaje). Ser√° necesario para que puedas autentificarte en la plataforma y subir tu modelo."
      ],
      "metadata": {
        "id": "3ad07BcWo7x3"
      },
      "id": "3ad07BcWo7x3"
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown ‚ùó\n",
        "# Logeo a plataforma mediante token de acceso\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "D-X7gPJzo5vX"
      },
      "id": "D-X7gPJzo5vX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown ‚ùó\n",
        "# Esto env√≠a el modelo entrenado al repositorio de modelos de Hugging Face.\n",
        "trainer.push_to_hub()"
      ],
      "metadata": {
        "id": "RDnfp1vSo6-s"
      },
      "id": "RDnfp1vSo6-s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJ4bJC4VPwCi"
      },
      "source": [
        "## 4.2 - ¬øC√≥mo personalizar un modelo GPT?\n",
        "\n",
        "\n",
        "- Se inicia por alg√∫n modelo pre-entrenado para la tarea espec√≠fica que uno busca (e.g. clasificaci√≥n, generaci√≥n, etc).\n",
        "- Se toma un corpus especializado (anotado, revisado, etc.) y se entrena utilizando dicho corpus.\n",
        "- Intentaremos [entrenar que un modelo genere texto](https://github.com/huggingface/notebooks/blob/main/examples/language_modeling.ipynb) con el estilo de alguno de los conjuntos de datos disponibles para este taller.\n",
        "- Utilizaremos el modelo `DeepESP/gpt2-spanish` como base para espa√±ol y el modelo `gpt2` como base para ingl√©s.\n",
        "* A diferencia de la adaptaci√≥n de dominio realizada en el modelo BERT, los modelos de generaci√≥n de texto se entrenan utilizando la tarea auto-supervisada llamada [**Causal Language Modeling**](https://huggingface.co/docs/transformers/tasks/language_modeling).\n"
      ],
      "id": "NJ4bJC4VPwCi"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7V3QxDyzPwCr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "c0baec2eca4f4f05b4ae58bef795acf1",
            "e4b67b5d5d8b4051a99695f772b149b5",
            "9c1d50d11e6f46d2be082bb139c5f7d8",
            "8e08fe392f6f4cf79431d4bb954b6c96",
            "de7958f6284d46b0be147009e6975a2d",
            "6c90e6d295364f348272b571e7887df2",
            "edbf19785b92432a84c734a34e0fdfff",
            "3a89f6ec82f4452ca94cb8a796d6ee3d",
            "b1bfa48aa1be4435892f63e7b906eb05",
            "1c4d05780aa54e47aea6b439b52e53c5",
            "2b814fb269a44354828b03961c8f87e1",
            "44d41c66a0654938a6c03c7b277b26f0",
            "9cf13a36e5e94c7c970d050794809d40",
            "83ab1d2abfd2457087070d213442425c",
            "903160db4f3d4bc29f6743861e77bfa8",
            "4541ddd7efdc45ac8164fc94210b0a6e",
            "0becea5b7ee143798a44558fe1564d36",
            "4f4be2f818b7424eb648a945388a1dd5",
            "ee962aa0d93f49899f220801eaf06999",
            "74d03115be89474fb562bc7e2f682037",
            "e5597365eacc480e838526b9eef96a59",
            "fd7b8f908cdf45fa91b60627d93b977b",
            "92c132a73a204aa9b47eb801559a2b2b",
            "962176acc42f49b8a7867778c4e6ac05",
            "6a7981849a2945488d1a7613c944bee3",
            "42a302b8cf32461e8cc94f295b1aa8c2",
            "7262f7777fe64efaaf24993ad9ed3490",
            "008fbacee97440cd8949b2c18f055de6",
            "7cbd1c7a69fd4dc6a1714974b192789d",
            "9a4466ed014b40a8a8c25a23e62ec6e8",
            "7eb686f0fdb44bd3b67dc3950219bce0",
            "644369261c9346529ac13e565704e65c",
            "a870bfb5345e4446944a82d0891bd5c0",
            "b8962d01cf2646bf93cdc7ad3e5230f9",
            "a643301a6dc7410e8b2db648e6021d6c",
            "e601c15164f542feb48f50d248a53ccd",
            "03506b294c924048b8af3246fd5ab8a1",
            "ef655dbada424270b028a83b3e850072",
            "a8b7f85c3cb6441d9f8c5431a9c65235",
            "4e8a8955a04a4192a445005dd2c86505",
            "89bc69bb43e242f39477fdef3bdc39df",
            "49f1624095924015ac6fb802245ba0ad",
            "f34bcae7a590483c88e479b8e2ba2714",
            "3c9601df15ac407eb221a4f6d2e4d1cb",
            "055bf7e69d9d40b0b5cc4b5af0ccdeff",
            "df00876de07844bf851a2b8e92318a47",
            "d2b299060c4f4f3cb6adec11f4707112",
            "3b24aaf04ba2479d96b22231f125ecd6",
            "c440d1e2abb64f4bafcb67332ff00008",
            "5c5e43d40af24cb8a23f435094ce3e7a",
            "cad27f945ca74ea7aef12b4753cb614a",
            "cee0e0dc3da14f76812d49781d27ccbe",
            "7109b8641023428982883df32632e9be",
            "776b6c222b294828b78f10bf8ed3a70c",
            "088b2b664573486187e65b41a157757a",
            "f36eb0ce0b194c4caf4fa6e853321dc9",
            "205427d4acc648f3ba3264ae40d5a2d3",
            "1dd80d7f28b04212aac6393fb26c95d5",
            "a9a83726517645aa99682f85ae04db56",
            "1a9eaaeaaea34c61912faa62ba788103",
            "8a59e6b0307a4cb59189b241e98413d6",
            "07393ddf19b4428187d00776b82d43d4",
            "5a195083aadc47b1a74945b112c4d1c8",
            "9810eb51e0c640babce1b00f99a42ef3",
            "7dbfb8bfc663406585ec73f7113c8d97",
            "c0d1d8ed939c4b79b88dcc09540e121f"
          ]
        },
        "outputId": "026225e0-5fcd-4df4-b7fd-75ed570dd7a5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (‚Ä¶)okenizer_config.json:   0%|          | 0.00/115 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0baec2eca4f4f05b4ae58bef795acf1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (‚Ä¶)lve/main/config.json:   0%|          | 0.00/914 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44d41c66a0654938a6c03c7b277b26f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (‚Ä¶)olve/main/vocab.json:   0%|          | 0.00/840k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92c132a73a204aa9b47eb801559a2b2b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (‚Ä¶)olve/main/merges.txt:   0%|          | 0.00/499k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8962d01cf2646bf93cdc7ad3e5230f9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (‚Ä¶)cial_tokens_map.json:   0%|          | 0.00/262 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "055bf7e69d9d40b0b5cc4b5af0ccdeff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/261M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f36eb0ce0b194c4caf4fa6e853321dc9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @markdown ‚ùó\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "BASE_MODEL = \"DeepESP/gpt2-spanish\" # @param [\"DeepESP/gpt2-spanish\", \"gpt2\"]\n",
        "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
        "model = AutoModelForCausalLM.from_pretrained(BASE_MODEL)"
      ],
      "id": "7V3QxDyzPwCr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDWpWGNuPwCs"
      },
      "source": [
        "### Probando el Modelo Base\n",
        "\n",
        "- Antes de ajustar el modelo vemos c√≥mo se desenvuelve si le damos como entrada el primer dato del dataset elegido."
      ],
      "id": "RDWpWGNuPwCs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PYTSVt0PwCv"
      },
      "outputs": [],
      "source": [
        "# @markdown üîé\n",
        "\n",
        "# Fijamos semilla para reproducibilidad de resultados\n",
        "torch.manual_seed(42)\n",
        "\n",
        "input_ids = tokenizer.encode(\"Ayer, al depertarme\", return_tensors='pt')\n",
        "sampling_output = model.generate(input_ids, do_sample=True, max_length=50, top_k=50, top_p=0.95, pad_token_id=tokenizer.eos_token_id)\n",
        "output = tokenizer.decode(sampling_output[0], skip_special_tokens=True)\n",
        "\n",
        "print(output)"
      ],
      "id": "6PYTSVt0PwCv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LKlbQIhPwCx"
      },
      "source": [
        "* Utilizaremos la librer√≠a `datasets` de HuggingFace para cargar cada uno de los corpus seleccionados.\n",
        "* Para la personalizaci√≥n de GPT, tenemos un total de 6 conjuntos de datos, todos en espa√±ol:\n",
        "    * Julio Cort√°zar (es):\n",
        "      * ‚âà 14k oraciones.\n",
        "      * Extra√≠do de una selecci√≥n de libros y cuentos del autor argentino.\n",
        "    * Edgar Allan Poe (es):\n",
        "      * ‚âà 48k oraciones.\n",
        "      * Extra√≠do de una selecci√≥n de libros y cuentos del autor estadounidense traducidos al espa√±ol.\n",
        "    * Jos√© Saramago (es):\n",
        "      * ‚âà 105k oraciones.\n",
        "      * Extra√≠do de una selecci√≥n de libros y cuentos del autor portugu√©s traducidos al espa√±ol.\n",
        "    * Peppa Pig (es):\n",
        "      * ‚âà 3k oraciones.\n",
        "      * Extra√≠do de subt√≠tulos de 77 episodios.\n",
        "    * Martin Fierro (es):\n",
        "      * ‚âà 2k oraciones.\n",
        "      * Extra√≠do del libro completo de Jos√© Hern√°ndez\n",
        "    * Rese√±as de Vinos (es):\n",
        "      * ‚âà 130k oraciones.\n",
        "      * Extra√≠do de descripciones de vinos de todo el mundo.\n",
        "\n",
        "* A continuaci√≥n, seleccionen de la lista desplegable el dataset que mas nos interese.\n",
        "* En `max_samples`, elijan un l√≠mite m√°ximo de datos para acotar el c√≥mputo necesario.\n",
        "* Autom√°ticamente el siguiente c√≥digo dividir√° el dataset elegido en dos partes:\n",
        "    * El 80% como conjunto de entrenamiento.\n",
        "    * El 20% como conjunto de test.\n"
      ],
      "id": "9LKlbQIhPwCx"
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown ‚ùó\n",
        "# @title  { run: \"auto\" }\n",
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "# Fijamos semilla para reproducibilidad de resultados\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Recolecci√≥n de par√°metros de formulario\n",
        "dataset_name = \"Jose Saramago (es)\" # @param [\"Rese√±as de Vinos (es)\", \"VizWiz (en)\", \"Martin Fierro (es)\", \"Peppa Pig (es)\", \"Julio Cortazar (es)\", \"Edgar Allan Poe (es)\", \"Jose Saramago (es)\"]\n",
        "max_samples = 30000 # @param {type:\"number\"}\n",
        "name_to_file = {\n",
        "    'Referencias de Vinos (es)' : \"wines_es.csv\",\n",
        "    'Martin Fierro (es)'        : \"martin_fierro.csv\",\n",
        "    'Peppa Pig (es)'            : \"peppa_pig.csv\",\n",
        "    'Julio Cortazar (es)'       : \"cortazar.csv\",\n",
        "    'Edgar Allan Poe (es)'      : \"poe.csv\",\n",
        "    'Jose Saramago (es)'        : \"saramago.csv\",\n",
        "}\n",
        "\n",
        "# Carga de conjunto de datos\n",
        "gpt2_ds = load_dataset(\n",
        "    path=DATASETS_PATH,\n",
        "    data_files={'all_data': name_to_file[dataset_name]},\n",
        ")\n",
        "\n",
        "# Divisi√≥n de conjunto de datos en subconjuntos de entrenamiento y testeto\n",
        "total_size = min(max_samples, len(gpt2_ds['all_data']))\n",
        "val_size = int(total_size *.2)\n",
        "train_size = total_size - val_size\n",
        "\n",
        "gpt2_ds = gpt2_ds[\"all_data\"].train_test_split(\n",
        "    train_size=train_size,\n",
        "    test_size=val_size,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "print(f\"* Informaci√≥n del dataset '{dataset_name}':\\n---\")\n",
        "gpt2_ds"
      ],
      "metadata": {
        "id": "1P7fdicp9j3E"
      },
      "execution_count": null,
      "outputs": [],
      "id": "1P7fdicp9j3E"
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown üîé\n",
        "# Visualizaci√≥n de primeros 15 ejemplos del dataset\n",
        "for sample in gpt2_ds['train']['samples'][:15]:\n",
        "    print(f\">> {sample}\")"
      ],
      "metadata": {
        "id": "QiiUUp1o_e8N"
      },
      "execution_count": null,
      "outputs": [],
      "id": "QiiUUp1o_e8N"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFCk1XZEPwC5"
      },
      "source": [
        "### Tokenizando los datos"
      ],
      "id": "RFCk1XZEPwC5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Al igual que en la primera parte de este taller, tokenizaremos el dataset. Para m√°s detalles de este proceso, ir a la secci√≥n `Tokenizaci√≥n de datos` en la primera mitad de este notebook.\n",
        "- Realizaremos un histograma de la cantidad de tokens de cada ejemplo, y utilizaremos esa informaci√≥n para realizar posteriormente la tokenizaci√≥n del dataset completo.\n"
      ],
      "metadata": {
        "id": "EU_OrPFP0Oot"
      },
      "id": "EU_OrPFP0Oot"
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown ‚ùó\n",
        "# Generaci√≥n de histograma del n√∫mero de tokens por ejemplos\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# C√°lculo de n√∫mero de tokens por ejemplos\n",
        "def count_tokens_fn(batch):\n",
        "    tokenized_batch = tokenizer(batch['samples'])\n",
        "    tokenized_batch['count'] = [len(tks) for tks in tokenized_batch['input_ids']]\n",
        "    return tokenized_batch\n",
        "\n",
        "result = gpt2_ds.map(\n",
        "    function=count_tokens_fn,\n",
        "    batched=True\n",
        ")\n",
        "\n",
        "num_of_tokens_list = result['train']['count'] + result['test']['count']\n",
        "\n",
        "# Generaci√≥n de histograma\n",
        "plt.hist(num_of_tokens_list, bins=35, edgecolor='k')\n",
        "plt.xlabel('N√∫mero de Tokens')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.title('N√∫mero de Tokens por Ejemplo')\n",
        "plt.show()\n",
        "\n",
        "# C√°lculo de percentiles (e.g., 25th, 50th, and 75th percentiles)\n",
        "percentiles = np.percentile(num_of_tokens_list, [25, 50, 75])\n",
        "\n",
        "print(f\"Total de ejemplos: {len(num_of_tokens_list)}\")\n",
        "print(f\"Percentil 25: {percentiles[0]}\")\n",
        "print(f\"Percentil 50 (Mediana): {percentiles[1]}\")\n",
        "print(f\"Percentile 75: {percentiles[2]}\")\n",
        "print(f\"Max: {np.max(num_of_tokens_list)}\")"
      ],
      "metadata": {
        "id": "gW1ZBper0F-4"
      },
      "id": "gW1ZBper0F-4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- En `MAX_TOKEN_LENGTH` podr√°n elegir el largo m√°ximo de cada dato. Truncando todos aquellos m√°s largos, y realizando padding para aquellos m√°s cortos."
      ],
      "metadata": {
        "id": "eIi-I4dP0Hrb"
      },
      "id": "eIi-I4dP0Hrb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0FrWUgDPwC5",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# @markdown ‚ùó\n",
        "# Tokenicaci√≥n de conjunto de datos completo\n",
        "\n",
        "# N√∫mero m√°ximo de tokens a utilizar\n",
        "MAX_TOKEN_LENGTH = 30 # @param {type:\"slider\", min:8, max:128, step:8}\n",
        "\n",
        "def tokenize_data_fn(batch):\n",
        "    tokenized_sample = tokenizer(\n",
        "        batch['samples'],\n",
        "        max_length=MAX_TOKEN_LENGTH,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    tokenized_sample[\"labels\"] = tokenized_sample['input_ids'].clone()\n",
        "    return tokenized_sample\n",
        "\n",
        "tokenized_gpt2_ds = gpt2_ds.map(\n",
        "    function=tokenize_data_fn,\n",
        "    batched=True,\n",
        "    remove_columns=[\"samples\"]\n",
        ")\n",
        "\n",
        "print(tokenized_gpt2_ds)"
      ],
      "id": "M0FrWUgDPwC5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8Xg_DgOPwC9"
      },
      "source": [
        "### Decodificando\n",
        "\n",
        "- Podemos ver que los textos pasan a estar agrupados en bloques de `MAX_TOKEN_LENGTH` tokens.\n",
        "- Adem√°s, vemos que el texto fue reemplazado por n√∫meros (√≠ndices en el vocabulario).\n",
        "- Por √∫ltimo, si decodificamos estos n√∫meros, obtenemos el texto original."
      ],
      "id": "q8Xg_DgOPwC9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ivXS3A6PwC9",
        "outputId": "dedeb5fa-4271-4e61-a45a-bb965633e754"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30\n",
            "[5438, 318, 268, 8800, 774, 388, 2241, 23, 11301, 970]\n"
          ]
        }
      ],
      "source": [
        "# @markdown üîé\n",
        "print(len(tokenized_gpt2_ds['train'][0]['input_ids']))\n",
        "print(tokenized_gpt2_ds['train'][0]['input_ids'][:10])"
      ],
      "id": "2ivXS3A6PwC9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDT-FvqGPwC-",
        "outputId": "f9bdd7b6-9263-41e7-b638-5789aff9fd35",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gesto de ra√≠z volteriana. A√±os antes, en Ensayo sobre la lucidez (2004), se hab√≠a adentrado en la inconsistencia y las des\n"
          ]
        }
      ],
      "source": [
        "# @markdown üîé\n",
        "print(tokenizer.decode(tokenized_gpt2_ds['train'][0]['input_ids']))"
      ],
      "id": "CDT-FvqGPwC-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Imydgb_2PwC_"
      },
      "source": [
        "### Entrenamiento\n",
        "\n",
        "- Una vez definido el conjunto de datos, pasamos a la parte m√°s intensa computacionalmente, el entrenamiento.\n",
        "- Podemos decidir guardar el modelo localmente o hacer un backup de cada √©poca del modelo en Hugging Face.\n",
        "- Definimos las propiedades del entrenamiento mediante [`TrainingArguments`](https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/trainer#transformers.TrainingArguments).\n",
        "- Definimos el entrenamiento del modelo mediante [`Trainer`](https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/trainer#transformers.Trainer).\n",
        "    - El entrenamiento tardar√° desde unos segundos hasta varias horas dependiendo el poder de c√≥mputo, par√°metros elegidos y tama√±o del dataset."
      ],
      "id": "Imydgb_2PwC_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PastX4Q8PwDA"
      },
      "outputs": [],
      "source": [
        "# @markdown ‚ùó‚è≥\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "LEARNING_RATE = 2e-5 # @param {type:\"number\"}\n",
        "EPOCHS = 5 # @param {type:\"slider\", min:3, max:15, step:1}\n",
        "\n",
        "model_name = dataset_name.replace(\" \", \"-\")[:-5]\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    model_name,\n",
        "    evaluation_strategy='epoch',\n",
        "    num_train_epochs=EPOCHS,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=5\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(BASE_MODEL)\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_gpt2_ds['train'],\n",
        "    eval_dataset=tokenized_gpt2_ds['test']\n",
        ")\n",
        "\n",
        "trainer.args._n_gpu = 1\n",
        "\n",
        "trainer.train()"
      ],
      "id": "PastX4Q8PwDA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Ahora ser√° necesario ingresar a la plataforma HuggingFace ü§ó para subir nuestro modelo. Luego podr√°n utilizarlo tanto en este taller con la librer√≠a `transformers` como compartir con sus amigos en la versi√≥n web."
      ],
      "metadata": {
        "id": "sx_77z2zVFGk"
      },
      "id": "sx_77z2zVFGk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhV7SE2SPwDB"
      },
      "outputs": [],
      "source": [
        "# @markdown ‚ùó\n",
        "\n",
        "# Logeo a plataforma mediante token de acceso\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "id": "FhV7SE2SPwDB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOknhZZ9PwDD"
      },
      "outputs": [],
      "source": [
        "# @markdown ‚ùó\n",
        "\n",
        "# Esto env√≠a el modelo entrenado al repositorio de modelos de Hugging Face.\n",
        "trainer.push_to_hub()\n",
        "tokenizer.push_to_hub(model_name)"
      ],
      "id": "wOknhZZ9PwDD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0cGM72OPwDE"
      },
      "source": [
        "### Probando el Nuevo Modelo\n",
        "\n",
        "- Ahora que tenemos el modelo entrenado, la pregunta es, ¬øC√≥mo se comportar√°?\n",
        "- Para ello volvemos a hacer la prueba anterior, quiz√°s esta vez con mejores resultados.\n",
        "- En `MODEL` deber√°n pegar el link al modelo que acaban de subir. Tendr√° un formato del estilo `username/modelName`."
      ],
      "id": "E0cGM72OPwDE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAlb6ROyPwDF"
      },
      "outputs": [],
      "source": [
        "# @markdown ‚ùó\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "MODEL = \"guidoivetta/Peppa-Pig\" # @param {type:\"string\"}\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL)"
      ],
      "id": "xAlb6ROyPwDF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- En esta celda podr√°n probar su modelo. Les incentivamos a ser creativos con las frases que elijan para completarla y comparar los resultados del modelo base con el modelo adaptado."
      ],
      "metadata": {
        "id": "mFQwGpKQWVIz"
      },
      "id": "mFQwGpKQWVIz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sinm67n3PwDH"
      },
      "outputs": [],
      "source": [
        "# @markdown ‚ùó\n",
        "\n",
        "# Fijamos semilla para reproducibilidad de resultados\n",
        "torch.manual_seed(42)  # To ensure determinism\n",
        "\n",
        "input_ids = tokenizer.encode(\"Ayer al despertarme\", return_tensors='pt')\n",
        "sampling_output = model.generate(input_ids, do_sample=True, max_length=50, top_k=50, top_p=0.95, pad_token_id=tokenizer.eos_token_id)\n",
        "output = tokenizer.decode(sampling_output[0], skip_special_tokens=True)\n",
        "\n",
        "print(output)"
      ],
      "id": "sinm67n3PwDH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Este trabajo est√° licenciado bajo la [Licencia MIT](https://github.com/nanom/llm_adaptation_workshop/blob/main/LICENSE).\n"
      ],
      "metadata": {
        "id": "dscWR-DCGhVV"
      },
      "id": "dscWR-DCGhVV"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "celltoolbar": "Slideshow",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "rise": {
      "scroll": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c0baec2eca4f4f05b4ae58bef795acf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4b67b5d5d8b4051a99695f772b149b5",
              "IPY_MODEL_9c1d50d11e6f46d2be082bb139c5f7d8",
              "IPY_MODEL_8e08fe392f6f4cf79431d4bb954b6c96"
            ],
            "layout": "IPY_MODEL_de7958f6284d46b0be147009e6975a2d"
          }
        },
        "e4b67b5d5d8b4051a99695f772b149b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c90e6d295364f348272b571e7887df2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_edbf19785b92432a84c734a34e0fdfff",
            "value": "Downloading (‚Ä¶)okenizer_config.json: 100%"
          }
        },
        "9c1d50d11e6f46d2be082bb139c5f7d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a89f6ec82f4452ca94cb8a796d6ee3d",
            "max": 115,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1bfa48aa1be4435892f63e7b906eb05",
            "value": 115
          }
        },
        "8e08fe392f6f4cf79431d4bb954b6c96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c4d05780aa54e47aea6b439b52e53c5",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2b814fb269a44354828b03961c8f87e1",
            "value": " 115/115 [00:00&lt;00:00, 2.96kB/s]"
          }
        },
        "de7958f6284d46b0be147009e6975a2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c90e6d295364f348272b571e7887df2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edbf19785b92432a84c734a34e0fdfff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a89f6ec82f4452ca94cb8a796d6ee3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1bfa48aa1be4435892f63e7b906eb05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c4d05780aa54e47aea6b439b52e53c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b814fb269a44354828b03961c8f87e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44d41c66a0654938a6c03c7b277b26f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9cf13a36e5e94c7c970d050794809d40",
              "IPY_MODEL_83ab1d2abfd2457087070d213442425c",
              "IPY_MODEL_903160db4f3d4bc29f6743861e77bfa8"
            ],
            "layout": "IPY_MODEL_4541ddd7efdc45ac8164fc94210b0a6e"
          }
        },
        "9cf13a36e5e94c7c970d050794809d40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0becea5b7ee143798a44558fe1564d36",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4f4be2f818b7424eb648a945388a1dd5",
            "value": "Downloading (‚Ä¶)lve/main/config.json: 100%"
          }
        },
        "83ab1d2abfd2457087070d213442425c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee962aa0d93f49899f220801eaf06999",
            "max": 914,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74d03115be89474fb562bc7e2f682037",
            "value": 914
          }
        },
        "903160db4f3d4bc29f6743861e77bfa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5597365eacc480e838526b9eef96a59",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_fd7b8f908cdf45fa91b60627d93b977b",
            "value": " 914/914 [00:00&lt;00:00, 42.8kB/s]"
          }
        },
        "4541ddd7efdc45ac8164fc94210b0a6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0becea5b7ee143798a44558fe1564d36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f4be2f818b7424eb648a945388a1dd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee962aa0d93f49899f220801eaf06999": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74d03115be89474fb562bc7e2f682037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e5597365eacc480e838526b9eef96a59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd7b8f908cdf45fa91b60627d93b977b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92c132a73a204aa9b47eb801559a2b2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_962176acc42f49b8a7867778c4e6ac05",
              "IPY_MODEL_6a7981849a2945488d1a7613c944bee3",
              "IPY_MODEL_42a302b8cf32461e8cc94f295b1aa8c2"
            ],
            "layout": "IPY_MODEL_7262f7777fe64efaaf24993ad9ed3490"
          }
        },
        "962176acc42f49b8a7867778c4e6ac05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_008fbacee97440cd8949b2c18f055de6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_7cbd1c7a69fd4dc6a1714974b192789d",
            "value": "Downloading (‚Ä¶)olve/main/vocab.json: 100%"
          }
        },
        "6a7981849a2945488d1a7613c944bee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a4466ed014b40a8a8c25a23e62ec6e8",
            "max": 840253,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7eb686f0fdb44bd3b67dc3950219bce0",
            "value": 840253
          }
        },
        "42a302b8cf32461e8cc94f295b1aa8c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_644369261c9346529ac13e565704e65c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a870bfb5345e4446944a82d0891bd5c0",
            "value": " 840k/840k [00:00&lt;00:00, 9.92MB/s]"
          }
        },
        "7262f7777fe64efaaf24993ad9ed3490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "008fbacee97440cd8949b2c18f055de6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cbd1c7a69fd4dc6a1714974b192789d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a4466ed014b40a8a8c25a23e62ec6e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7eb686f0fdb44bd3b67dc3950219bce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "644369261c9346529ac13e565704e65c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a870bfb5345e4446944a82d0891bd5c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8962d01cf2646bf93cdc7ad3e5230f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a643301a6dc7410e8b2db648e6021d6c",
              "IPY_MODEL_e601c15164f542feb48f50d248a53ccd",
              "IPY_MODEL_03506b294c924048b8af3246fd5ab8a1"
            ],
            "layout": "IPY_MODEL_ef655dbada424270b028a83b3e850072"
          }
        },
        "a643301a6dc7410e8b2db648e6021d6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8b7f85c3cb6441d9f8c5431a9c65235",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_4e8a8955a04a4192a445005dd2c86505",
            "value": "Downloading (‚Ä¶)olve/main/merges.txt: 100%"
          }
        },
        "e601c15164f542feb48f50d248a53ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89bc69bb43e242f39477fdef3bdc39df",
            "max": 498530,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49f1624095924015ac6fb802245ba0ad",
            "value": 498530
          }
        },
        "03506b294c924048b8af3246fd5ab8a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f34bcae7a590483c88e479b8e2ba2714",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3c9601df15ac407eb221a4f6d2e4d1cb",
            "value": " 499k/499k [00:00&lt;00:00, 24.3MB/s]"
          }
        },
        "ef655dbada424270b028a83b3e850072": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8b7f85c3cb6441d9f8c5431a9c65235": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e8a8955a04a4192a445005dd2c86505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89bc69bb43e242f39477fdef3bdc39df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49f1624095924015ac6fb802245ba0ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f34bcae7a590483c88e479b8e2ba2714": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c9601df15ac407eb221a4f6d2e4d1cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "055bf7e69d9d40b0b5cc4b5af0ccdeff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df00876de07844bf851a2b8e92318a47",
              "IPY_MODEL_d2b299060c4f4f3cb6adec11f4707112",
              "IPY_MODEL_3b24aaf04ba2479d96b22231f125ecd6"
            ],
            "layout": "IPY_MODEL_c440d1e2abb64f4bafcb67332ff00008"
          }
        },
        "df00876de07844bf851a2b8e92318a47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c5e43d40af24cb8a23f435094ce3e7a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cad27f945ca74ea7aef12b4753cb614a",
            "value": "Downloading (‚Ä¶)cial_tokens_map.json: 100%"
          }
        },
        "d2b299060c4f4f3cb6adec11f4707112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cee0e0dc3da14f76812d49781d27ccbe",
            "max": 262,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7109b8641023428982883df32632e9be",
            "value": 262
          }
        },
        "3b24aaf04ba2479d96b22231f125ecd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_776b6c222b294828b78f10bf8ed3a70c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_088b2b664573486187e65b41a157757a",
            "value": " 262/262 [00:00&lt;00:00, 4.79kB/s]"
          }
        },
        "c440d1e2abb64f4bafcb67332ff00008": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c5e43d40af24cb8a23f435094ce3e7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cad27f945ca74ea7aef12b4753cb614a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cee0e0dc3da14f76812d49781d27ccbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7109b8641023428982883df32632e9be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "776b6c222b294828b78f10bf8ed3a70c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "088b2b664573486187e65b41a157757a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f36eb0ce0b194c4caf4fa6e853321dc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_205427d4acc648f3ba3264ae40d5a2d3",
              "IPY_MODEL_1dd80d7f28b04212aac6393fb26c95d5",
              "IPY_MODEL_a9a83726517645aa99682f85ae04db56"
            ],
            "layout": "IPY_MODEL_1a9eaaeaaea34c61912faa62ba788103"
          }
        },
        "205427d4acc648f3ba3264ae40d5a2d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a59e6b0307a4cb59189b241e98413d6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_07393ddf19b4428187d00776b82d43d4",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "1dd80d7f28b04212aac6393fb26c95d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a195083aadc47b1a74945b112c4d1c8",
            "max": 261499792,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9810eb51e0c640babce1b00f99a42ef3",
            "value": 261499792
          }
        },
        "a9a83726517645aa99682f85ae04db56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dbfb8bfc663406585ec73f7113c8d97",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c0d1d8ed939c4b79b88dcc09540e121f",
            "value": " 261M/261M [00:02&lt;00:00, 92.0MB/s]"
          }
        },
        "1a9eaaeaaea34c61912faa62ba788103": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a59e6b0307a4cb59189b241e98413d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07393ddf19b4428187d00776b82d43d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a195083aadc47b1a74945b112c4d1c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9810eb51e0c640babce1b00f99a42ef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7dbfb8bfc663406585ec73f7113c8d97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0d1d8ed939c4b79b88dcc09540e121f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}